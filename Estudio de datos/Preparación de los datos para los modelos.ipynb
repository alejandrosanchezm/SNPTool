{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación del dataset para la posterior creación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se convierten las variables categóricas a numéricas y se crea un One Hot Encoding de cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import list_functions as lf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#### Para mostrar todas las columnas\n",
    "pd.set_option('display.max_columns', None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 34798 entries, 0 to 12166\n",
      "Columns: 168 entries, ref to patho\n",
      "dtypes: float64(126), int64(37), object(5)\n",
      "memory usage: 44.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r'datasets/studied_benign.csv',low_memory=False)\n",
    "df2 = pd.read_csv(r'datasets/studied_patho.csv',low_memory=False)\n",
    "\n",
    "del df1['Unnamed: 0']\n",
    "del df2['Unnamed: 0'] # Índices de los dataframes anteriores\n",
    "\n",
    "df1['patho'] = 0\n",
    "df2['patho'] = 1\n",
    "df = pd.concat([df1,df2])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos una comprobación previa para ver si los dos datasets tienen las mismas columnas, y eliminamos aquellas columnas que en ambos datasets tengan al menos un 50% de nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(lf.notCommonBothLists(list(df1.columns), list(df2.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 34787 entries, 0 to 12166\n",
      "Columns: 168 entries, ref to patho\n",
      "dtypes: float64(126), int64(37), object(5)\n",
      "memory usage: 44.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(axis=0,subset=['hg19_chr','hg19_pos(1-based)','ref','alt','aaref','aaalt'],inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificación de las variables categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos la variable 'hg19_chr' en numérica sustituyendo el valor del cromosoma 'X' por el valor 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 10 11 12 13 14 15 16 17 18 19  2 20 21 22  3  4  5  6  7  8  9 23]\n"
     ]
    }
   ],
   "source": [
    "df['hg19_chr'].replace({\"X\": \"23.0\"}, inplace=True)\n",
    "df['hg19_chr'] = df['hg19_chr'].astype(float).astype(int)\n",
    "print(df['hg19_chr'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificamos los valores de las bases de las variables 'ref' y 'alt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'C': 1, 'G': 2, 'T': 3}\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df[['ref','alt']].stack().unique())\n",
    "\n",
    "df['ref_code'] = le.transform(df['ref'])\n",
    "df['alt_code'] = le.transform(df['alt'])\n",
    "\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificamos los valores de los aminoácidos de las variables 'aaref' y 'aaalt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9, 'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18, 'X': 19, 'Y': 20}\n"
     ]
    }
   ],
   "source": [
    "lea = LabelEncoder()\n",
    "lea.fit(df[['aaref','aaalt']].stack().unique())\n",
    "\n",
    "df['aaref_code'] = lea.transform(df['aaref'])\n",
    "df['aaalt_code'] = lea.transform(df['aaalt'])\n",
    "\n",
    "lea_name_mapping = dict(zip(lea.classes_, lea.transform(lea.classes_)))\n",
    "print(lea_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos columnas de One Hot Encoding para las bases, aminoácidos y cromosomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# OHE de los cromosomas\n",
    "dummy = pd.get_dummies(df['hg19_chr'], prefix='hg19_chr')\n",
    "df = pd.concat([df,dummy],axis=1)\n",
    "\n",
    "# OHE de las bases\n",
    "dummy = pd.get_dummies(df['ref'], prefix='ref')\n",
    "df = pd.concat([df,dummy],axis=1)\n",
    "dummy = pd.get_dummies(df['alt'], prefix='alt')\n",
    "df = pd.concat([df,dummy],axis=1)\n",
    "\n",
    "# OHE de los aminoácidos\n",
    "dummy = pd.get_dummies(df['aaref'], prefix='aaref')\n",
    "df = pd.concat([df,dummy],axis=1)\n",
    "dummy = pd.get_dummies(df['aaalt'], prefix='aaalt')\n",
    "df = pd.concat([df,dummy],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportamos el dataset actual (preprocesado)\n",
    "\n",
    "De esta forma, para posteriores modelos no tener que ejecutar el código anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\alejs\\OneDrive\\Documentos\\GitHub\\TFG\\datasets\\model_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
